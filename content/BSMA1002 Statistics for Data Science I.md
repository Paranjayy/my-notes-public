---
tags:
  - course
  - statistics
---

# BSMA1002 Statistics for Data Science I

**Course Credits**: 4

**Course Type**: Foundational

**Instructor**: Usha Mohan

**Pre-requisites**: None

## Overview
Students explore large datasets and learn how to extract insights from data. Basic probability is introduced along with random variables and key distributions.

## Learning Objectives
- Create, download and analyse data sets
- Frame questions using variables and cases
- Describe data using numerical summaries and visualisations
- Estimate chance using probability laws
- Model real-world situations with probability
- Calculate expectation and variance of random variables
- Apply properties of the Binomial and Normal distributions

## Course Structure
12 weeks of coursework with weekly online assignments, two invigilated quizzes and one invigilated end term exam.

## Weekly Topics
1. **Introduction & Data Types** – scope of statistics, population vs. sample, scales of measurement and how to summarise data
2. **Categorical Data** – constructing frequency tables, bar charts and pie charts, interpreting mode and median for qualitative variables
3. **Numerical Data** – building histograms and ogives, computing mean, median, quartiles, percentiles and measures of spread such as variance and IQR
4. **Association Between Variables** – contingency tables and relative frequencies, scatterplots, covariance, Pearson and point-biserial correlation coefficients
5. **Counting Principles** – addition rule, multiplication rule, permutations with repetition, factorial notation
6. **Permutations & Combinations** – selecting objects without order vs. with order, combinatorial identities and real-world examples
7. **Probability Basics** – classical and empirical definitions of probability, events, complements, unions, intersections and laws of probability
8. **Conditional Probability** – independence, total probability, Bayes’ theorem, medical test examples and tree diagrams
9. **Random Variables** – discrete vs. continuous variables, probability mass and cumulative distribution functions, support and range
10. **Expectation & Variance** – computing the mean and variance of discrete variables, linearity of expectation and indicator variables
11. **Binomial & Poisson Distributions** – Bernoulli trials, binomial coefficients, approximations using the Poisson distribution
12. **Continuous Random Variables** – probability density functions, uniform, exponential and normal distributions with applications

## Glossary
- **Probability Mass Function (PMF)**: function that gives the probability for each possible value of a discrete random variable.
- **Cumulative Distribution Function (CDF)**: probability that a random variable is less than or equal to a given value.
- **Bayes’ Theorem**: method for updating probabilities based on new evidence.

## Reference Texts
- *Introductory Statistics* (10th Edition) by Neil A. Weiss
- *Introductory Statistics* (4th Edition) by Sheldon M. Ross
- *Descriptive Statistics (VOL 1)* and *Probability and Probability Distributions (VOL 2)*

## Additional Topics
- **Sampling Methods** – simple random, stratified and cluster sampling with pros and cons
- **Transformations** – logarithmic and square-root transformations to stabilise variance
- **Hypothesis Testing** – null vs. alternative hypotheses, p-values and significance levels

## Further Reading
- *Statistics* by Freedman, Pisani and Purves
